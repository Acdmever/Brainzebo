Brainzebo Project Work
By Luis Cordero (lacordero@dal.ca or armandocorder@gmail.com)

NOTE: There may be some scripts or projects hard to understand or make use of. Please contact me at if you need help, I'd be happy to help.

Github repo: https://github.com/Acdmever/Brainzebo
Lab database (Need username): 129.173.66.49

Classifiers: Using python and python notebooks. These are the Valence and Arousal and Motor Imagery Classifiers. They can use OpenBCI or Emotiv data. Implemented to send values to a socket via OSC (For unity or other uses). The latest version of the Motor Imagery Classifier is not in the PC, check the repo or lab database. Also, the datasets will be in the PC and the database, not in Git

Gazbraino Demo: Unity demo that visualizes Valence-Arousal values in Unity, and also changes music effects.

Vibropixel: Haptic hardware Joe gave to to check out and see if we can make use of. We weren't able to make them work, but the software for them is here.

Manuals: Setup manuals for hardware and software.

OpenBCI work: My first project with OpenBCI and Max, uses EEG band values to change light intensity and colours, and also changes MIDI effects of music. You can also use the Senso Gloves to change MIDI Effects. 

SensoGloves: My first senso gloves project, it tries to replicate playing piano in VR. Doesn;t work well since the Gloves were not able to be tracked by the Vibe Lighthouse. (Even though they are supposed to)

